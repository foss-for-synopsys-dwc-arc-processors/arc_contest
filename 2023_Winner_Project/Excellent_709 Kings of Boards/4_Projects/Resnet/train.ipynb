{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b748d78-4719-421f-890f-76570f173f79",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d6342-003c-4b21-a220-6f671707dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Add, BatchNormalization, Activation, Flatten, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-reducing",
   "metadata": {},
   "source": [
    "## Load and preprocess training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf73db-1418-4f34-8b95-eb5ca24e17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "    # Print with Markdowns    \n",
    "    display(Markdown(string))\n",
    "    \n",
    "def load_images_from_folder(folder,only_path = False, label = \"\"):\n",
    "# Load the paths to the images in a directory\n",
    "# or load the images\n",
    "    if only_path == False:\n",
    "        images = []\n",
    "        for filename in os.listdir(folder):\n",
    "            img = plt.imread(os.path.join(folder,filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        return images\n",
    "    else:\n",
    "        path = []\n",
    "        for filename in os.listdir(folder):\n",
    "            img_path = os.path.join(folder,filename)\n",
    "            if img_path is not None:\n",
    "                path.append([label,img_path])\n",
    "        return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b6eb6-0435-4ab7-b444-bfb89f8c4625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_train = []\n",
    "images_test = []\n",
    "# dirp = \"/kaggle/input/fruits/fruits-360_dataset/fruits-360/Training\"\n",
    "\n",
    "dir_train = \"./fruits/train/\"\n",
    "dir_test = \"./fruits/test/\"\n",
    "\n",
    "skip_list = []\n",
    "\n",
    "for folder in os.listdir(dir_train):\n",
    "    if folder in skip_list: continue\n",
    "    \n",
    "    images_train += load_images_from_folder(dir_train+folder, True, label = folder)\n",
    "\n",
    "for folder in os.listdir(dir_test):\n",
    "    if folder in skip_list: continue\n",
    "    \n",
    "    images_test += load_images_from_folder(dir_test+folder, True, label = folder)\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(images_train, columns = [\"food\", \"path\"])\n",
    "df_test = pd.DataFrame(images_test, columns = [\"food\", \"path\"])\n",
    "\n",
    "# Shuffle the dataset\n",
    "from sklearn.utils import shuffle\n",
    "df_train = shuffle(df_train, random_state = 0)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = shuffle(df_test, random_state = 0)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "fruit_names = []\n",
    "for folder in os.listdir(dir_train):\n",
    "    fruit_names.append(folder)\n",
    "\n",
    "mapper_fruit_names = dict(zip(fruit_names, [t for t in range(len(fruit_names))]))\n",
    "df_train[\"label\"] = df_train[\"food\"].map(mapper_fruit_names)\n",
    "df_test[\"label\"] = df_test[\"food\"].map(mapper_fruit_names)\n",
    "\n",
    "df_train[\"food\"].value_counts()\n",
    "df_test[\"food\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299554c-b039-4983-8359-2975d947d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 144\n",
    "RGBSETTINGS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff71a2-8f78-443f-9d99-0b5b87daeec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(df):\n",
    "    img_paths = df[\"path\"].values       # path\n",
    "    img_labels = df[\"label\"].values     # label\n",
    "    img_food = df[\"food\"].values      # food\n",
    "    X = []                              \n",
    "    y = []\n",
    "\n",
    "    for i, path in enumerate(img_paths):\n",
    "        \n",
    "        img = plt.imread(path)\n",
    "        if RGBSETTINGS == 1:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        label = img_labels[i]\n",
    "        \n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-object",
   "metadata": {},
   "source": [
    "## Load and process training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-jersey",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset preprocessing #1\n",
    "train_images_database, train_labels_database = load_img(df_train)\n",
    "test_images_database, test_labels_database = load_img(df_test)\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (img_size, img_size, RGBSETTINGS)\n",
    "# Transfer to nparray\n",
    "train_images = train_images_database.astype('float32')\n",
    "train_labels = to_categorical(train_labels_database, num_classes, dtype = 'float32')\n",
    "test_images = test_images_database.astype('float32')\n",
    "test_labels = to_categorical(test_labels_database, num_classes, dtype = 'float32')\n",
    "\n",
    "train_images = (train_images - 128.0) / 128.0\n",
    "\n",
    "test_images = (test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-edinburgh",
   "metadata": {},
   "source": [
    "## Model define and create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699afb09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the residual block\n",
    "def residual_block(inputs, filters):\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Adjust dimensions if needed\n",
    "    # if inputs.shape[-1] != filters:\n",
    "    inputs = Conv2D(filters, kernel_size=(1, 1), padding='same')(inputs)\n",
    "    \n",
    "    x = Add()([x, inputs])\n",
    "    # x = Activation('relu')(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    x = Dropout(0.45)(x)\n",
    "    return x\n",
    "\n",
    "# Build the ResNet model\n",
    "def build_resnet(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = Conv2D(8, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = residual_block(x, filters=16)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = residual_block(x, filters=16)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = residual_block(x, filters=32)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = residual_block(x, filters=32)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(num_classes, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Define the input shape and number of classes\n",
    "input_shape = (img_size, img_size, RGBSETTINGS)  # Modify according to your input image size\n",
    "num_classes = 10  # Modify according to your number of classes\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_resnet(input_shape, num_classes)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-topic",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-dover",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training model\n",
    "\n",
    "#optimizer = 'RMSprop'\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Set training\n",
    "model.fit(train_images, train_labels,\n",
    "          validation_split = 0.2,\n",
    "          batch_size = 200,\n",
    "          verbose = 1,\n",
    "          epochs = 50\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "score = model.evaluate(test_images, test_labels, verbose = 0)\n",
    "\n",
    "print('test loss', score[0])\n",
    "print('accuracy', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-tourism",
   "metadata": {},
   "source": [
    "# Save weights of this model  \n",
    "model.save_weights('my_model.h5')\n",
    "\n",
    "# load weights to this TensorFlow model  \n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-postage",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save model and weights of this model\n",
    "model.save('model_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lOAD model and weights of this model\n",
    "model_2 = keras.models.load_model('model_save')\n",
    "\n",
    "# Model Evaluation\n",
    "score = model_2.evaluate(test_images, test_labels, verbose = 0)\n",
    "print('test loss', score[0])\n",
    "print('accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-mechanism",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-copyright",
   "metadata": {},
   "source": [
    "## Reload and preprocess images in TFLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and testing from dataset_buffer\n",
    "\n",
    "test_images = (test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-silly",
   "metadata": {},
   "source": [
    "## Convert model into TFLM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.cast(test_images, tf.float32)\n",
    "tf_lite_ds = tf.data.Dataset.from_tensor_slices((test_images)).batch(1) #construct a dataset \n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in tf_lite_ds.take(100):\n",
    "        yield [input_value]\n",
    "    \n",
    "converter.representative_dataset = representative_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "converted_model = converter.convert()\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"emnist_model_int8.tflite\"\n",
    "converted_model_file.write_bytes(converted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-carrier",
   "metadata": {},
   "source": [
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use **xxd** utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "cd generated/\n",
    "xxd -i emnist_model_int8.tflite > model.h\n",
    "```\n",
    "\n",
    "The model is ready to be integrated into TFLM application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02953ef6-3b16-48ba-8a71-1e4081b74b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-animation",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate TensorFlow Lite INT-8 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-choir",
   "metadata": {},
   "source": [
    "Full test set contains 14800 samples. Evaluating int8 model on it might take more than 10 minutes. \n",
    "If you want to get estimation faster, please, limit number of samples to be evaluated by reducing **max_samples** value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a68486",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = int(len(test_images) * 1.0)\n",
    "\n",
    "print(max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"emnist_model_int8.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(converted_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    scale, zero_point = interpreter.get_output_details()[0]['quantization']\n",
    "    # print(scale, zero_point)\n",
    "    prediction_values = []\n",
    "    \n",
    "    for tflm_test_image in test_images[:max_samples]:\n",
    "        # Pre-processing: add batch dimension, quantize and convert inputs to int8 to match with\n",
    "        # the model's input data format.\n",
    "        tflm_test_image = np.expand_dims(tflm_test_image, axis=0) #.astype(np.float32)\n",
    "        tflm_test_image = np.int8(tflm_test_image / scale + zero_point)\n",
    "        interpreter.set_tensor(input_index, tflm_test_image)\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Find the letter with highest probability\n",
    "        output = interpreter.tensor(output_index)\n",
    "        result = np.argmax(output()[0])\n",
    "        prediction_values.append(result)\n",
    "    \n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_values)):\n",
    "        print(prediction_values[index], ans_test_labels[index])\n",
    "        if prediction_values[index] == ans_test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_values)\n",
    "\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and testing from dataset_buffer\n",
    "tflm_test_images = test_images_database\n",
    "ans_test_labels = test_labels_database\n",
    "\n",
    "def thinning(image):\n",
    "    return np.where(image < 210.0, 0, 255)\n",
    "\n",
    "tflm_test_images = (tflm_test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amino-inflation",
   "metadata": {},
   "source": [
    "Please, keep in mind that full test dataset evaluation on int8 model may take several minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-extension",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-treasury",
   "metadata": {},
   "source": [
    "Evaluate the accuracy without normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training and testing from dataset_buffer\n",
    "tflm_test_images = test_images_database\n",
    "ans_test_labels = test_labels_database\n",
    "\n",
    "tflm_test_images = (tflm_test_images - 128.0) / 128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-construction",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-seventh",
   "metadata": {},
   "source": [
    "## Create a test set for target application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Import training and testing from dataset_buffer\n",
    "test_images = test_images_database\n",
    "test_labels = test_labels_database\n",
    "\n",
    "test_images = test_images.reshape([test_images.shape[0], img_size, img_size, RGBSETTINGS])\n",
    "\n",
    "num_of_samples = 25\n",
    "random_test_images = random.sample(range(1, test_images.shape[0]), num_of_samples)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 10))\n",
    "rows = 5\n",
    "cols = 5\n",
    "\n",
    "for index in range(0, num_of_samples):\n",
    "    img = test_images[random_test_images[index]]\n",
    "    fig.add_subplot(rows, cols, (index + 1))\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = open(\"generated/test_samples.cpp\", \"w\")\n",
    "\n",
    "samples_file.write(\"#include \\\"test_samples.h\\\"\\n\\n\")\n",
    "samples_file.write(\"const int kNumSamples = \" + str(num_of_samples) + \";\\n\\n\")\n",
    "\n",
    "samples = \"\" \n",
    "samples_array = \"const TestSample test_samples[kNumSamples] = {\"\n",
    "\n",
    "for sample_idx, img_idx in enumerate(random_test_images, 1):\n",
    "    img_arr = list(np.ndarray.flatten(test_images[img_idx]))\n",
    "    var_name = \"sample\" + str(sample_idx)\n",
    "    samples += \"TestSample \" + var_name + \" = {\\n\" #+ \"[IMAGE_SIZE] = { \"\n",
    "    samples += \"\\t.label = \" + str(test_labels[img_idx]) + \",\\n\" \n",
    "    samples += \"\\t.image = {\\n\"\n",
    "    wrapped_arr = [img_arr[i:i + 20] for i in range(0, len(img_arr), 20)]\n",
    "    for sub_arr in wrapped_arr:\n",
    "        samples += \"\\t\\t\" + str(sub_arr)\n",
    "    samples += \"\\t}\\n};\\n\\n\"    \n",
    "    samples_array += var_name + \", \"\n",
    "    \n",
    "samples = samples.replace(\"[\", \"\")\n",
    "samples = samples.replace(\"]\", \",\\n\")\n",
    "samples_array += \"};\\n\"\n",
    "\n",
    "samples_file.write(samples);\n",
    "samples_file.write(samples_array);\n",
    "samples_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-commonwealth",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-syria",
   "metadata": {},
   "source": [
    "You have converted a Tensorflow model into TFLM format and generated a test set for the application. Now you can copy generated files into target application of this tutorial and try it out:\n",
    "\n",
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use **xxd** utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "cd generated/\n",
    "xxd -i emnist_model_int8.tflite > model.h\n",
    "```\n",
    "\n",
    "The model is ready to be integrated into TFLM application.\n",
    "\n",
    "* copy *generated/model.h* to *../inc* and *generated/test_samples.cpp* to *../src*\n",
    "* You can start to integrate your WE-I project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -i generated/emnist_model_int8.tflite > model.h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
