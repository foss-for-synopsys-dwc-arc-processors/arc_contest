{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Gay_ZewfDEdJ",
   "metadata": {
    "id": "Gay_ZewfDEdJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IZKkiRUxDEdO",
   "metadata": {
    "id": "IZKkiRUxDEdO"
   },
   "source": [
    "## Load and preprocess training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "er65qngdDEdP",
   "metadata": {
    "id": "er65qngdDEdP"
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"res.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Lw38Kk9KDEdQ",
   "metadata": {
    "id": "Lw38Kk9KDEdQ",
    "outputId": "fe491bc0-da38-45db-a896-b4b7b48c6d8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "      <th>six</th>\n",
       "      <th>seven</th>\n",
       "      <th>eight</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>53</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>74</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>71</td>\n",
       "      <td>96</td>\n",
       "      <td>77</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>73</td>\n",
       "      <td>96</td>\n",
       "      <td>75</td>\n",
       "      <td>54</td>\n",
       "      <td>24</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  two  three  four  five  six  seven  eight  cls\n",
       "0   33   20     53    95    70   48     22     34    0\n",
       "1   30   28     70    96    74   49     26     37    0\n",
       "2   39   27     71    96    77   55     25     37    0\n",
       "3   38   25     73    96    75   54     24     36    0\n",
       "4   36   26     57    95    75   55     19     31    0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twIKkFSDDEdR",
   "metadata": {
    "id": "twIKkFSDDEdR"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "MwOyKrpkDEdS",
   "metadata": {
    "id": "MwOyKrpkDEdS"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index(drop=True)\n",
    "train_features = train_data.copy()\n",
    "train_labels = train_features.pop(\"cls\")\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "test_features = test_data.copy()\n",
    "test_labels = test_features.pop(\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ZCS0RZZdDEdS",
   "metadata": {
    "id": "ZCS0RZZdDEdS",
    "outputId": "f62f5ec5-e3fd-44f6-fbad-f42c640cc89b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>five</th>\n",
       "      <th>six</th>\n",
       "      <th>seven</th>\n",
       "      <th>eight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>77</td>\n",
       "      <td>184</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>87</td>\n",
       "      <td>196</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>197</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>76</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>93</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>98</td>\n",
       "      <td>197</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>139</td>\n",
       "      <td>114</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>79</td>\n",
       "      <td>187</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     one  two  three  four  five  six  seven  eight\n",
       "0     37    2     30    77   184   63     37     38\n",
       "1     13    0     92    84    25   27      2     35\n",
       "2     23    1     52    87   196   37      0     41\n",
       "3     29    0     45    94   197   43      0     42\n",
       "4     38   25     70    95    76   55     25     36\n",
       "..   ...  ...    ...   ...   ...  ...    ...    ...\n",
       "475   31   13     64    93    28   22      2     38\n",
       "476   19   10     63    93    27   12      0     35\n",
       "477   40    3     53    98   197   40      3     40\n",
       "478   38    0     41   139   114   42      1     37\n",
       "479   45    0     30    79   187   64     35     36\n",
       "\n",
       "[480 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uFAWT5JoDEdT",
   "metadata": {
    "id": "uFAWT5JoDEdT"
   },
   "source": [
    "## Load and process training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sXJupDj3DEdT",
   "metadata": {
    "id": "sXJupDj3DEdT"
   },
   "outputs": [],
   "source": [
    "# Transfer to nparray\n",
    "num_classes = 6\n",
    "train_features = train_features.values.astype(\"float32\")\n",
    "train_labels_one_hot = to_categorical(train_labels, num_classes, dtype=\"float32\")\n",
    "test_features = test_features.values.astype(\"float32\")\n",
    "test_labels_one_hot = to_categorical(test_labels, num_classes, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qb1shQyHDEdU",
   "metadata": {
    "id": "qb1shQyHDEdU"
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # Normalize the value first\n",
    "    max_num = np.amax(x)\n",
    "    x = x / max_num\n",
    "    x = (x * 255) - 128\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "RtQ_F165DEdV",
   "metadata": {
    "id": "RtQ_F165DEdV"
   },
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "train_features = normalize(train_features)\n",
    "test_features = normalize(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "RR699ea-DEdV",
   "metadata": {
    "id": "RR699ea-DEdV",
    "outputId": "0c378cca-7d39-4b18-8033-a7d79d5e6d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -90.259995 -125.96      -97.4      ...  -63.739998  -90.259995\n",
      "   -89.240005]\n",
      " [-114.74     -128.        -34.159996 ... -100.46     -125.96\n",
      "   -92.3     ]\n",
      " [-104.54     -126.98      -74.96     ...  -90.259995 -128.\n",
      "   -86.18    ]\n",
      " ...\n",
      " [ -87.2      -124.94      -73.94     ...  -87.2      -124.94\n",
      "   -87.2     ]\n",
      " [ -89.240005 -128.        -86.18     ...  -85.16     -126.98\n",
      "   -90.259995]\n",
      " [ -82.1      -128.        -97.4      ...  -62.719994  -92.3\n",
      "   -91.28    ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QSNj4pXRDEdW",
   "metadata": {
    "id": "QSNj4pXRDEdW"
   },
   "source": [
    "## Model define and create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "-C5LDJd9DEdX",
   "metadata": {
    "id": "-C5LDJd9DEdX"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# FC1\n",
    "model.add(Input(shape=(8,), dtype=tf.float32))\n",
    "model.add(Dense(64, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# FC2\n",
    "model.add(Dense(128, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# FC3\n",
    "model.add(Dense(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "-3XAP-WmDEdX",
   "metadata": {
    "id": "-3XAP-WmDEdX",
    "outputId": "bb745939-adc0-429c-e59e-258d232180fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLay  (None, 8)                3         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " quant_dense (QuantizeWrappe  (None, 64)               515       \n",
      " rV2)                                                            \n",
      "                                                                 \n",
      " quant_batch_normalization (  (None, 64)               259       \n",
      " QuantizeWrapperV2)                                              \n",
      "                                                                 \n",
      " quant_activation (QuantizeW  (None, 64)               3         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_1 (QuantizeWrap  (None, 128)              8195      \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_batch_normalization_1  (None, 128)              515       \n",
      "  (QuantizeWrapperV2)                                            \n",
      "                                                                 \n",
      " quant_activation_1 (Quantiz  (None, 128)              3         \n",
      " eWrapperV2)                                                     \n",
      "                                                                 \n",
      " quant_dense_2 (QuantizeWrap  (None, 6)                779       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,272\n",
      "Trainable params: 9,862\n",
      "Non-trainable params: 410\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tfmot.quantization.keras.quantize_model(model)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BP5gbx3eDEdY",
   "metadata": {
    "id": "BP5gbx3eDEdY"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4osX4flODEdZ",
   "metadata": {
    "id": "4osX4flODEdZ"
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "atpepvgcDEdZ",
   "metadata": {
    "id": "atpepvgcDEdZ",
    "outputId": "c4e7a28b-8f80-435f-a2f0-a8db1053aea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 1.4157 - accuracy: 0.4521 - val_loss: 3.3593 - val_accuracy: 0.1583\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.9500 - val_loss: 4.2289 - val_accuracy: 0.1583\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1965 - accuracy: 0.9812 - val_loss: 4.1479 - val_accuracy: 0.1750\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9875 - val_loss: 3.7760 - val_accuracy: 0.1833\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9875 - val_loss: 3.4584 - val_accuracy: 0.2167\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9937 - val_loss: 3.0899 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9937 - val_loss: 2.6784 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9979 - val_loss: 2.3112 - val_accuracy: 0.4417\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.4750\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9958 - val_loss: 1.7729 - val_accuracy: 0.5750\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9958 - val_loss: 1.5681 - val_accuracy: 0.6083\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9958 - val_loss: 1.3803 - val_accuracy: 0.6167\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9958 - val_loss: 1.1967 - val_accuracy: 0.6250\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0235 - accuracy: 0.9979 - val_loss: 1.0518 - val_accuracy: 0.6250\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9979 - val_loss: 0.9326 - val_accuracy: 0.6333\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.8191 - val_accuracy: 0.6417\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.7094 - val_accuracy: 0.6500\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9979 - val_loss: 0.5930 - val_accuracy: 0.7083\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.5365 - val_accuracy: 0.7333\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.4606 - val_accuracy: 0.7917\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.8250\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9083\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9417\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.2083 - val_accuracy: 0.9667\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9979 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9979 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "# Define optimizer loss function and merics \n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# Set training\n",
    "history = model.fit(\n",
    "    train_features, train_labels_one_hot, \n",
    "    validation_data=(test_features, test_labels_one_hot), batch_size=64,\n",
    "    verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bH2LOItFDEda",
   "metadata": {
    "id": "bH2LOItFDEda",
    "outputId": "20a2aba5-0b37-460f-94c5-bee1c5651cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 995us/step - loss: 0.0012 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.001241261255927384, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6t8YhpoBDEdb",
   "metadata": {
    "id": "6t8YhpoBDEdb",
    "outputId": "a826e22d-d9b9-4d07-e75f-2c66aaea2e50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEWCAYAAABPON1ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn10lEQVR4nO3deXxU9b3/8ddnJhshIQsEQghh35EExA0VrUuLrWurta0L4HatbW9Xvba3tra1t7beq7VeH1V+1r1uV2tLtWq1oKDiArKIEAQUJOwEkkBC1vn+/jiTECCQISSZMzPv5+ORRzIzZ875nDnJe775zvd8jznnEBER/wpEuwARETk8BbWIiM8pqEVEfE5BLSLicwpqERGfU1CLiPicglpijpk5Mxse/vk+M7slkmU7sJ3LzOyfHa1TpLOYxlFLNJjZy8B7zrmfHXD/BcD9QKFzrvEQz3XACOfcmgi2E9GyZjYY+BRIPtR2RaJFLWqJlkeAy83MDrj/CuDPCkuRfRTUEi1/BXoDpzbfYWY5wLnAbDNbYGYVZrbZzP7XzFLaWomZPWxmt7W6fWP4OZvM7KoDlv2SmS02syoz22Bmt7Z6eF74e4WZ7TGzk8xshpm92er5U8zsfTOrDH+f0uqx183sV2b2lpntNrN/mlmfjr88IvsoqCUqnHN7gWeAK1vd/VWgFNgDfB/oA5wEnAnc0N46zWwa8CPgbGAEcNYBi1SHt5cNfAn4ppldGH5savh7tnMuwzm34IB15wIvAn/Ae4O5E3jRzHq3WuwbwEygL5ASrkXkqCmoJZoeAS42s7Tw7SuBR5xzi5xz7zjnGp1z6/D6rE+LYH1fBR5yzi13zlUDt7Z+0Dn3unPuQ+dcyDm3DHgywvWCF+yrnXOPhet6Eu9N5bxWyzzknPu41ZtQSYTrFjksBbVEjXPuTWAHcKGZDQOOB54ws5Fm9oKZbTGzKuC/8FrX7SkANrS6vb71g2Z2gpnNNbPtZlYJXB/hepvXvf6A+9YDA1rd3tLq5xogI8J1ixyWglqi7VG8lvTlwCvOua3AH/FaqyOcc72AnwAHfujYls3AwFa3iw54/AlgNjDQOZcF3Ndqve0Nf9oEDDrgviJgYwR1iRwVBbVE26N4fcnX4nWFAGQCVcAeMxsNfDPCdT0DzDCzsWaWDvz8gMczgZ3OuVozOx6vT7nZdiAEDD3Euv8BjDSzb5hZkpldCowFXoiwNpEOU1BLVIX7oN8GeuK1dsH7EO4bwG7g/wFPR7iul4DfA3OANeHvrd0A/NLMdgM/wwv25ufWAL8G3gqPNjnxgHWX441I+SFQDtwEnOuc2xHhrop0mE54ERHxObWoRUR8TkEtIuJzCmoREZ9TUIuI+FxSV6y0T58+bvDgwV2xahGRuLRo0aIdzrm8th7rkqAePHgwCxcu7IpVi4jEJTM78MzXFur6EBHxOQW1iIjPKahFRHyuS/qoRSR+NTQ0UFZWRm1tbbRLiUlpaWkUFhaSnJwc8XMU1CJyRMrKysjMzGTw4MEcfCU1ORznHOXl5ZSVlTFkyJCIn6euDxE5IrW1tfTu3Vsh3QFmRu/evY/4vxEFtYgcMYV0x3XktfNtUM8t3cbKzVXRLkNEJOp8G9T/8dwyLnvgXTbsrIl2KSLiMxkZiXWVM18GtXOOndX17Kyu57rHFlFT3xjtkkREosaXQb27rpHGkOO0kXms2lLFjf+3DF3gQEQO5JzjxhtvZPz48RxzzDE8/bR3MaDNmzczdepUSkpKGD9+PPPnz6epqYkZM2a0LHvXXXdFufrI+XJ4XkV1AwDnFRcwZVhvfvNSKRPfzOaaUw91OTsRiYZf/P0jVmzq3M+Sxhb04ufnjYto2b/85S8sWbKEpUuXsmPHDo477jimTp3KE088wRe+8AX+8z//k6amJmpqaliyZAkbN25k+fLlAFRUVHRq3V3Jly3qXTX1AOSkJ3Pd1KFMLMrm78s2R7kqEfGbN998k69//esEg0H69evHaaedxvvvv89xxx3HQw89xK233sqHH35IZmYmQ4cO5ZNPPuE73/kOL7/8Mr169Yp2+RHzZYt6Zzios9NTMDNKBmbz9PsbCIUcgYCGBYn4RaQt3+42depU5s2bx4svvsiMGTP4wQ9+wJVXXsnSpUt55ZVXuO+++3jmmWd48MEHo11qRHzZoq4IB3VuzxQARudnUlPfxIZdGgEiIvuceuqpPP300zQ1NbF9+3bmzZvH8ccfz/r16+nXrx/XXnst11xzDR988AE7duwgFArxla98hdtuu40PPvgg2uVHzJct6l3hPuqcdO9c+FH53r8oKzfvZlDvnlGrS0T85aKLLmLBggUUFxdjZvzud78jPz+fRx55hDvuuIPk5GQyMjJ49NFH2bhxIzNnziQUCgHwm9/8JsrVRy7ioDazILAQ2OicO7frSvL6qAMGvdK8oB7ZLwMzWLVlN9PG53flpkUkBuzZswfwzvK74447uOOOO/Z7fPr06UyfPv2g58VSK7q1I+n6+C6wsqsKaW1XTT3Z6Skt/dHpKUkMyk1n1VadqSgiiSeioDazQuBLwANdW45nV3UD2en7TwE4Kj+T0s27u2PzIiK+EmmL+vfATUDoUAuY2XVmttDMFm7fvv2oitpVU09uesp+943O78W68mpqG5qOat0iIrGm3aA2s3OBbc65RYdbzjk3yzk32Tk3OS+vzQvpRmxXTQPZBwV1JiEHq7fuOap1i4jEmkha1CcD55vZOuAp4Awze7wri9pVXd8y4qPZqPxMAEq3qJ9aRBJLu0HtnPuxc67QOTcY+Bowxzl3eVcWtaumvmUMdbNBvXuSlhygdIv6qUUksfjuhJe99U3UNYYO6voIBoyR/TJZpaAWkQRzREHtnHu9q8dQ72w1z8eBRvXLVItaRLpNY6M/plj2XYt6V3U4qA/o+gCvn3rHnjp27Knr7rJExGcuvPBCjj32WMaNG8esWbMAePnll5k0aRLFxcWceeaZgHdyzMyZMznmmGOYMGECzz33HLD/xQeeffZZZsyYAcCMGTO4/vrrOeGEE7jpppt47733OOmkk5g4cSJTpkxh1apVADQ1NfGjH/2I8ePHM2HCBO655x7mzJnDhRde2LLeV199lYsuuuio99V3p5Dvmznv4KAeHT6VfNWW3fQZntqtdYlIG166GbZ82LnrzD8Gzrm93cUefPBBcnNz2bt3L8cddxwXXHAB1157LfPmzWPIkCHs3LkTgF/96ldkZWXx4Ydenbt27Wp33WVlZbz99tsEg0GqqqqYP38+SUlJvPbaa/zkJz/hueeeY9asWaxbt44lS5aQlJTEzp07ycnJ4YYbbmD79u3k5eXx0EMPcdVVVx3d64Evg3r/eT5aG92/eeTHbk4e3qdb6xIRf/nDH/7A888/D8CGDRuYNWsWU6dOZciQIQDk5uYC8Nprr/HUU0+1PC8nJ6fddV9yySUEg0EAKisrmT59OqtXr8bMaGhoaFnv9ddfT1JS0n7bu+KKK3j88ceZOXMmCxYs4NFHHz3qffVdUDfPnNdW10efjFT6ZKSwSkP0RPwhgpZvV3j99dd57bXXWLBgAenp6Zx++umUlJRQWloa8TpaXw28trZ2v8d69tw3+dstt9zC5z73OZ5//nnWrVvH6aefftj1zpw5k/POO4+0tDQuueSSliA/Gr7ro94Z7qPO7nFwixq87o8Vujq5SEKrrKwkJyeH9PR0SktLeeedd6itrWXevHl8+umnAC1dH2effTb33ntvy3Obuz769evHypUrCYVCLS3zQ21rwIABADz88MMt95999tncf//9LR84Nm+voKCAgoICbrvtNmbOnNkp++u7oK6oaSAzLYmkYNulHVOYRenm3TqVXCSBTZs2jcbGRsaMGcPNN9/MiSeeSF5eHrNmzeLLX/4yxcXFXHrppQD89Kc/ZdeuXYwfP57i4mLmzp0LwO233865557LlClT6N+//yG3ddNNN/HjH/+YiRMn7jcK5JprrqGoqIgJEyZQXFzME0880fLYZZddxsCBAxkzZkyn7K91xUVjJ0+e7BYuXNih5373qcUs2VDBGzd+rs3HX16+mesf/4Dnb5jCxKL2+5pEpHOtXLmy0wIoXn37299m4sSJXH311W0+3tZraGaLnHOT21redy3qndX1B53s0tqEwmwAlpVVdlNFIiKRO/bYY1m2bBmXX955J3D78MPEBvpkHDqo+2el0ScjlaVlFd1XlIhIhBYtOuz8dR3iuxb1rpr6NsdQNzMziguz1KIWiaKu6DJNFB157fwX1O10fYDX/bF2+x721Pnj9E6RRJKWlkZ5ebnCugOcc5SXl5OWlnZEz/NV10ddYxPV9U3k9mx7aF6zCQOzcA4+LKvkpGG9u6k6EQEoLCykrKyMo71ASKJKS0ujsLDwiJ7jq6CuCJ+V2F6LurjlA8UKBbVIN0tOTm45+0+6h6+6Pg43z0druT1TKMzpoX5qEUkI/grq6vA8H+10fYDXqtbIDxFJBP4K6ghb1AATCrMo27WXck15KiJxLoaDOhuAZRvV/SEi8c1XQb3vw8T2uz6OKczCDJZtUFCLSHzzVVDvrK4nPSVIWnKw3WUzUpMYlpfBMvVTi0ic81VQt3dW4oEmDMhi+Sa1qEUkvvkrqKvrIxrx0Wx0/0y2VtW1XGdRRCQe+SuoaxqOqEXdfA1FXZlcROKZr4K6oqb9eT5aG53ffA1FXfFFROKXr4J6Z3U9uRGM+GiWl5lKbs8UVqlFLSJxzDdB7Zzj7LH5TBoU+VVbzIzR+ZmsVFCLSBzzzaRMZsb/fLX4iJ83Kj+Tp97bQCjkCASs/SeIiMQY37SoO2pMfi/2NjTx2c6aaJciItIlYj6oR/fXB4oiEt9iPqhH9M3EDFZuVj+1iMSnmA/qHilBhvTuqRa1iMStmA9q8Lo/NERPROJVXAT1qH69WL+zhmpd7FZE4lBcBPXo/pk4Bx9vVataROJPXAT1mPCcH+r+EJF4FBdBXZjTg/SUoCZnEpG4FBdBHQgYo/IzWblZIz9EJP7ERVCDN5Peqq27cc5FuxQRkU4VN0E9vG8mFTUNlOsiAiISZ9oNajNLM7P3zGypmX1kZr/ojsKO1PC+GQCs2bYnypWIiHSuSFrUdcAZzrlioASYZmYndmlVHaCgFpF41e40p87r9G1Ov+Twl+86gvv3SiM9JaigFpG4E1EftZkFzWwJsA141Tn3bhvLXGdmC81s4fbt2zu5zPYFAsbQvJ6s3a6gFpH4ElFQO+eanHMlQCFwvJmNb2OZWc65yc65yXl5eZ1cZmSG52WoRS0iceeIRn045yqAucC0LqnmKA3vm8Hmylr2aM4PEYkjkYz6yDOz7PDPPYCzgdIurqtDmj9Q/ETdHyISRyJpUfcH5prZMuB9vD7qF7q2rI7RyA8RiUeRjPpYBkzshlqO2qDePUkKmIJaROJK3JyZCJAcDDCod7qCWkTiSlwFNXjdH2vURy0icSQug3p9eQ31jaFolyIi0iniMqibQo715dXRLkVEpFPEX1DnZQIa+SEi8SPugnpoXk9AQS0i8SPugrpnahIFWWn6QFFE4kbcBTXAsL4ZmpxJROJGXAb18L4ZrN1WTSjku9lYRUSOWFwG9ej8TPY2NLFhV020SxEROWpxGdSj8nsBsHLz7ihXIiJy9OIyqEf2y8AMSrdURbsUEZGjFpdBnZ6SxODePSlVi1pE4kBcBjV4/dRqUYtIPIjjoO7F+p011NTrai8iEtviN6j7Z+IcfLxV46lFJLbFb1Dne3N+lG5W94eIxLa4DeqBOemkpwQp3aIPFEUktsVtUAcCxqj8TFaqRS0iMS5ugxq8DxRLt+zGOZ1KLiKxK66Dekz/TCr3NrC1qi7apYiIdFhcB/Xo5lPJNZ5aRGJYXAf1qH7NIz/0gaKIxK64Duqs9GQKstJ0hqKIxLS4DmqA0f17qUUtIjEt/oM6P5O12/dQ19gU7VJERDok7oN6/IAsGkNOc1OLSMyK+6CeVJQDwAfrd0W5EhGRjon7oM7PSqN/VhqLN1REuxQRkQ6J+6AGr1WtFrWIxKqECOqJRdlsrNjLtqraaJciInLEEiSow/3Un1VEtxARkQ5IiKAeV9CL5KCxeIO6P0Qk9iREUKclBxlXkMXi9RXRLkVE5IglRFCD10+9bGMFDU2haJciInJEEiaoJxXlUNsQ0unkIhJzEiaoJxZlA6ifWkRiTrtBbWYDzWyuma0ws4/M7LvdUVhnG5Ddg76ZqRpPLSIxJymCZRqBHzrnPjCzTGCRmb3qnFvRxbV1KjNjYlG2zlAUkZjTbovaObfZOfdB+OfdwEpgQFcX1hUmFeWwvryGHXt0aS4RiR1H1EdtZoOBicC7bTx2nZktNLOF27dv76TyOtcJQ3sD8Pba8ihXIiISuYiD2swygOeA7znnDrpkinNulnNusnNucl5eXmfW2GmOGZBFVo9k5n/szzcSEZG2RBTUZpaMF9J/ds79pWtL6jrBgHHK8D7MX70D51y0yxERiUgkoz4M+BOw0jl3Z9eX1LVOHdGHLVW1rNm2J9qliIhEJJIW9cnAFcAZZrYk/PXFLq6ry5wyog8Ab6j7Q0RiRLvD85xzbwLWDbV0i8KcdIbm9WT+6h1cc+rQaJcjItKuhDkzsbWpI/J499Nyaht0wVsR8b+EDOpTR/ShtiHEIp2lKCIxICGD+sShvUkOGvNWq59aRPwvIYO6Z2oSk4pymP/xjmiXIiLSroQMaoCpI/NYsbmK7bt1OrmI+FvCBvVpI72zJ+eUbo1yJSIih5ewQT2uoBeFOT14efmWaJciInJYCRvUZsa0cfm8taacqtqGaJcjInJICRvUANPG51PfFGJu6bZolyIickgJHdSTinLIy0zllY/U/SEi/pXQQR0IGJ8f24+5pdvZW6+zFEXEnxI6qMHr/tjb0KSTX0TEtxI+qE8c2pusHsm8otEfIuJTCR/UycEAZ43px2srt1LfGIp2OSIiB0n4oAav+6OqtpG31+qUchHxHwU13mx6mWlJzF66KdqliIgcREENpCUHmTYun39+tFVzVIuI7yiowy4oGcCeukbm6OQXEfEZBXXYScN60ycjldlL1P0hIv6ioA4LBozzivszZ9U2zf0hIr6ioG7l/OIC6htDGlMtIr6ioG6lZGA2RbnpGv0hIr6ioG7FzLigpIC31uzQlV9ExDcU1Ae4oKSAkIMXlqlVLSL+oKA+wPC+mYwr6MVfNfpDRHxCQd2GC0sGsHRDBZ9s3xPtUkREFNRtOb+kADPUqhYRX1BQt6FfrzSmDOvNXxdvxDkX7XJEJMEpqA/hwpIBfLazhsUbKqJdiogkOAX1IUwbn09qUoC/Lt4Y7VJEJMEpqA8hMy2Zs8b24+9LN9HQpAsKiEj0KKgP46KSAeyqaeCNVbqeoohEj4L6MKaOzCMvM5VHFqyLdikiksAU1IeRkhRgxpTBzF+9gxWbqqJdjogkKAV1Oy4/YRDpKUEemP9JtEsRkQSloG5HVnoylx43kNlLN7G5cm+0yxGRBKSgjsBVJw/BAQ+/tS7apYhIAlJQR2BgbjpfPKY/T7z7Gbt19RcR6WbtBrWZPWhm28xseXcU5FfXnTqU3XWNPP7OZ9EuRUQSTCQt6oeBaV1ch+8dU5jF50bl8cfX11BRUx/tckQkgSS1t4Bzbp6ZDe6GWnzv5nPGcM7d87hnzhpuOXdsdIqoLIMlT0B9dXS2LyKHlpIBp93Y6attN6gjZWbXAdcBFBUVddZqfWVUfiaXHDuQRxes48qTBjGod8/u23jVZnjzTlj0MDQ1QDCl+7YtIpHJ6OvvoHbOzQJmAUyePDlu5wb9wedHMnvpJn73yiru/cakrt1YKASfvg6L/wwr/w6uCUq+Aaf+CHIGde22RcQ3Oi2oE0W/Xmlce+oQ/jBnDVefsotJRTmdv5GGWvjgEXj7HqjcAGnZMOlKOOlbkDuk87cnIr6m4XkdcN1pw+iTkcqvXljRuRcWaGqE9x+AP0yEl26CrIFw8YPww1Xwpf9WSIskqEiG5z0JLABGmVmZmV3d9WX5W0ZqEjd9YRSLP6vgb515ua4XfwAv/tDr1rhyNsz8B4z/CiSndd42RCTmRDLq4+vdUUisufjYQh57Zz2/eWklZ4/tR8/Uo+xFWvSw191xyvfhzJ+DWafUKSKxT10fHRQIGLeeP5atVXXc98bao1tZ2SL4x40w7Aw44xaFtIjsR0F9FI4dlMsFJQXcP+8TNuys6dhKKjfCM1dARj585U8QCHZukSIS8xTUR+nmc0YTNOO2F1cc2ROrd8A/fwr3HAs1O+HSxyA9t2uKFJGYpqA+Sv2zevDtM4bzykdbeePjCC/Z9f4D8PsJsOBeGHs+fPMtKCjp0jpFJHYpqDvBNacOYUifntw6+yPqGpsOvWAoBK/+zBvZMegkuOFd+PIs6D2s+4oVkZijoO4EqUlBbj1/HJ/uqOaB+Z+2vVBjPTz/b/DW3TD5avjGM5A3snsLFZGYpDMTO8lpI/OYNi6fe+as5sKJAxiQ3cN7YNd6bxKlpU9AxWdw5s/glB9oZIeIREwt6k50y3nejHq3vbACGuvg+W/C3RPgjd9C7jCvFX3qDxXSInJE1KLuRAOye3DD6cN54NXFVD3wE3pteQemfAeO/zfIHhjt8kQkRimoO1OoievGNPClN39Fjy2bCF00i0DxpdGuSkRinIL6SIRCsGcrVKz3+pt3rQ//HL5dWUZaqJGipJ5Mr7mJi5tO5svRrllEYp6CGsA52LQYytfuC91W4UvTYS691bMvZBfBgGNh3EWQPYjgkNOpfnIjv3t5FdPG55OeopdZRDousRPEOVj7L5j7X7Bx0b77e+ZB9iDoXwJjzoOkHq0e6wM5g71wzhoIKekHrTYA3HJuFhfft4A/vr6WH35+VFfviYjEscQN6qrN8H8zYMM7kFUE594FRVO8D/1Sjv4SW5MH53LRxAHcM2cNATO+d9YITKM9RKQDEjOonYO//ztsXuoFdMnlkNT51yD87VcmkBQw7v7XataXV/PbiyeQmqRJl0TkyCRmUC97Glb/E6bdDpOv6rLNpCQF+N3FExjcpyd3vLKKrVV1PDTzONKSFdYiErnEO+Fl9xZ46T9g4Ine+OYuZmZ863PDufOrxSz4pJwbn11GKBS31/4VkS6QWC1q57wJkRpr4YL/hUD3vU99eVIhW6vq+O3LpRTl9uDGL4zutm2LSGxLnKDe+Qm8fjuUvgBn/xL6jOj2Eq4/bSif7azm3rlrye+VxuUnDtIHjCLSrvgP6qpNMPfXsORJCCbDyd+FE78VlVLMjF9eMJ6NFbXc8rePePydz5hx8mAuLBlAjxT1W4tI28y5zu8vnTx5slu4cGGnr/eIhJpg4YPw2i+8E1YmXwWnfA8y86NbF1DX2MTflmziobfWsXJzFX0zU3num1MYmHvwmGwRSQxmtsg5N7nNx+IyqMvXenM/l70PQz/nDcHLHRK9eg7BOceCT8q5/rFFFGT34NlvTiHjaK9mLiIx6XBBHX+jPsrXwkNfhPI1cNEsuOJ5X4Y0eF0hU4b14d7LJrF62x6+//QSjQgRkYPEV1CXr4WHz4VQI8x8CYovjYm5n08dkcctXxrDqyu28j+vrop2OSLiM/Hzf/audfDI+d7QuxkvQN8x0a7oiEyfMphVW/dw79y1jOyXyQUlA6Jdkoj4RHy0qJ2D56+H+t0wfTb0Gxftio6YmfGL88dx/OBcbnp2GR+WVUa7JBHxifgI6pWz4bMFcNYvIP+YaFfTYSlJAf54+ST6ZKRy7aML2ba7NtoliYgPxH5QN9bBqz+DvmNh4hXRruao9c5I5f9dOZnKvQ3822OL2FvfFO2SRCTKYj+o35vl9U9/4dcQjI8u97EFvbjzq8Us2VDB1Y+8T019Y7RLEpEoiu2grt4Bb9wBIz4Pw86IdjWd6pxj+nPnV4t555NyZjz4PnvqFNYiiSp2g3rTEnhmOtTvgc/fFu1qusRFEwu5+2sTWfTZLqY/+B47qw9zSTARiVux01dQXw0VG7xujsWPeZMrpWXDuXdCXvxe6uq84gKSg8a/P7mEc+6ex12XljBlWJ9olyUi3chfp5Bv/cgbagfgQt7tdW/CuvnexWabpWbBlG/DCddDWq/OKdrnPtpUyXeeXMynO6q54fRhfO+skSQHY/cfIhHZX+zM9fHr/tBQs/99PXJg8CnehWabLyrbdwykZnZGqTGlpr6RX8xewdMLNzA6P5PfXTyBCYXZ0S5LRDpB7AR16YverHfNcodA33HdOsF/LPjnR1u45W/L2b67jqtPGcJ3zxqpyZxEYlzsBLVErHJvA7e/VMqT731GdnoyV508hOlTBpPVIznapYlIByio49iSDRX875zVvLZyG5mpSZw9rh+nDO/DycP70K9XWrTLE5EIKagTwEebKnlg/qe88fH2lmF8A7J7MKZ/L8YW9GJcQS/GD8iiICtNl/8S8aHDBXVEHZtmNg24GwgCDzjnbu/E+qQTjCvI4q5LSwiFHCu3VPH2mnI+3FjJis1VzCndSvM017k9UxjeN4PCnB4MzEmnT2Yq6clB0lOCZKYl0zsjhT4ZqWT1SCY5aAp1ER9oN6jNLAjcC5wNlAHvm9ls59yKri5OjlwgYIwryGJcQVbLfXvrmyjdUsXyjZUs31jFpzuqWbC2nOerNnK4f6gCBmnJQdLCQe59JdGj+XZqEhmpSWSmJdEzJYmAeds3g5RggLTkIKlJARpDjrqGJuoaQ9Q1hqhvDFHfFCKrRzL9s9Lon9WDzLQkUpMCpCQFCAbaf3MwM5ICzV8BAgEIBoxAG28sZmAYDodzHLTPZt5zg2Y4IOTCy4WXP3A93nbQm5h0m0ha1McDa5xznwCY2VPABYCCOkb0SAkysSiHiUU5+91f3xiiYm89e+ubqKlvompvA+XV9ZTvqaNybwN1jSFqG5rY2+A9XlPXRHV9I3vrm9hc2UBNfSN76prYU9dAbUMo4noCBsnBAHWNkT/Hj5LCb0rNDPPeMMy8Nyy8MDc7+M2hWch7R8AB5q2EgHlvBMFAgGDAW6/3JrH/m4NzjsN1XLa3fMCsZUBVKLTvDQpoc3sHrd9o2bfW+9fcndr83EB4H9p8fsvP1lLfga+VwxFq41fFOUdDyNHYFKIx5GgKfzm8hkJKUoCUYKDlGBm0vBGHXPP+ea9D62N1uP3db9n9HvTW17tnKs9cf9KhV9JBkQT1AGBDq9tlwAkHLmRm1wHXARQVFXVKcdK1UpIC9M3snA8cm0Iu/Afg/bHXNYZaWtHJwUBLazk1KUBS+ESdmvpGtlTWsrmylj11jV5LuzFEUwSfmzjnaAw5Gpu876GQoym8/dZ/Qvta0a7lD7E5+Lz1hP9ww8/f94e4L2haB60L/5E3hgOitVB4Xc2B0bx8cwgfGHrNNQVahbn3+nnbaHKOpia3bx/2e27rMG3r9aHNEG9e3tvWvvqa3xwCZvttr2W/cQe9bq33jQNe19ah2NbhbP2m0bytlte9jdfqwOPWLDno/UcVDP93FQx4K2hodNQ3NVEfbgw0b6N5H5vX0/IG1Wqf2nhPaXkzbT42+x+L8L446NWja4bJdtpanXOzgFngfZjYWeuV2BAMGMFWv+FpyUFoZ6hgekoSQ/MyGJqX0dXlicS0SM4k2QgMbHW7MHyfiIh0g0iC+n1ghJkNMbMU4GvA7K4tS0REmrXb9eGcazSzbwOv4A3Pe9A591GXVyYiIkCEfdTOuX8A/+jiWkREpA2a7UhExOcU1CIiPqegFhHxOQW1iIjPdcnseWa2HVjf7oJt6wPs6MRyYkEi7jMk5n4n4j5DYu73ke7zIOdcXlsPdElQHw0zW3ioqf7iVSLuMyTmfifiPkNi7ndn7rO6PkREfE5BLSLic34M6lnRLiAKEnGfITH3OxH3GRJzvzttn33XRy0iIvvzY4taRERaUVCLiPicb4LazKaZ2SozW2NmN0e7nq5iZgPNbK6ZrTCzj8zsu+H7c83sVTNbHf6e0966Yo2ZBc1ssZm9EL49xMzeDR/zp8PT6MYVM8s2s2fNrNTMVprZSfF+rM3s++Hf7eVm9qSZpcXjsTazB81sm5ktb3Vfm8fWPH8I7/8yM5t0JNvyRVC3uoDuOcBY4OtmNja6VXWZRuCHzrmxwInAt8L7ejPwL+fcCOBf4dvx5rvAyla3fwvc5ZwbDuwCro5KVV3rbuBl59xooBhv/+P2WJvZAODfgcnOufF4UyN/jfg81g8D0w6471DH9hxgRPjrOuCPR7QlF75GWzS/gJOAV1rd/jHw42jX1U37/je8K7yvAvqH7+sPrIp2bZ28n4XhX9wzgBfwrky3A0hq63cgHr6ALOBTwh/at7o/bo81+66xmos3jfILwBfi9VgDg4Hl7R1b4H7g620tF8mXL1rUtH0B3QFRqqXbmNlgYCLwLtDPObc5/NAWoF+06uoivwduApqvCNsbqHDONYZvx+MxHwJsBx4Kd/k8YGY9ieNj7ZzbCPw38BmwGagEFhH/x7rZoY7tUWWcX4I64ZhZBvAc8D3nXFXrx5z3lhs34ybN7Fxgm3NuUbRr6WZJwCTgj865iUA1B3RzxOGxzgEuwHuTKgB6cnD3QELozGPrl6BOqAvomlkyXkj/2Tn3l/DdW82sf/jx/sC2aNXXBU4GzjezdcBTeN0fdwPZZtZ8laF4POZlQJlz7t3w7Wfxgjuej/VZwKfOue3OuQbgL3jHP96PdbNDHdujyji/BHXCXEDXzAz4E7DSOXdnq4dmA9PDP0/H67uOC865HzvnCp1zg/GO7Rzn3GXAXODi8GJxtc8AzrktwAYzGxW+60xgBXF8rPG6PE40s/Tw73rzPsf1sW7lUMd2NnBlePTHiUBlqy6S9kW7M75V5/oXgY+BtcB/RrueLtzPU/D+HVoGLAl/fRGvz/ZfwGrgNSA32rV20f6fDrwQ/nko8B6wBvg/IDXa9XXB/pYAC8PH+69ATrwfa+AXQCmwHHgMSI3HYw08idcP34D339PVhzq2eB+e3xvOtw/xRsVEvC2dQi4i4nN+6foQEZFDUFCLiPicglpExOcU1CIiPqegFhHxOQW1CGBmpzfP6ifiNwpqERGfU1BLTDGzy83sPTNbYmb3h+e43mNmd4XnQP6XmeWFly0xs3fC8/8+32pu4OFm9pqZLTWzD8xsWHj1Ga3mjv5z+Mw6zOz28Pzhy8zsv6O065LAFNQSM8xsDHApcLJzrgRoAi7Dm/hnoXNuHPAG8PPwUx4F/sM5NwHvbLDm+/8M3OucKwam4J1dBt5Mht/DmxN9KHCymfUGLgLGhddzW1fuo0hbFNQSS84EjgXeN7Ml4dtD8aZOfTq8zOPAKWaWBWQ7594I3/8IMNXMMoEBzrnnAZxztc65mvAy7znnypxzIbxT+wfjTdNZC/zJzL4MNC8r0m0U1BJLDHjEOVcS/hrlnLu1jeU6Oi9CXaufm/Amum8Ejseb+e5c4OUOrlukwxTUEkv+BVxsZn2h5fp0g/B+j5tnZvsG8KZzrhLYZWanhu+/AnjDObcbKDOzC8PrSDWz9ENtMDxveJZz7h/A9/EupyXSrZLaX0TEH5xzK8zsp8A/zSyAN2vZt/Am5D8+/Ng2vH5s8KaZvC8cxJ8AM8P3XwHcb2a/DK/jksNsNhP4m5ml4bXof9DJuyXSLs2eJzHPzPY45zKiXYdIV1HXh4iIz6lFLSLic2pRi4j4nIJaRMTnFNQiIj6noBYR8TkFtYiIz/1/mJFcAb432rYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Validation\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(\"valid.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RKJDVQrNDEdb",
   "metadata": {
    "id": "RKJDVQrNDEdb"
   },
   "source": [
    "#Save weights of this model  \n",
    "model.save_weights('my_model.h5')\n",
    "\n",
    "#load weights to this TensorFlow model  \n",
    "model.load_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "on7JGawrDEdc",
   "metadata": {
    "id": "on7JGawrDEdc",
    "outputId": "aeab1eac-b84e-4cb2-f42f-48308968115d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, activation_layer_call_fn, activation_layer_call_and_return_conditional_losses, dense_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_save\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model and weights of this model\n",
    "model.save(\"model_save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zFRuV2aMDEdc",
   "metadata": {
    "id": "zFRuV2aMDEdc"
   },
   "source": [
    "## Reload and preprocess images in TFLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aGRI94YADEdd",
   "metadata": {
    "id": "aGRI94YADEdd",
    "scrolled": true
   },
   "source": [
    "## Convert model into TFLM format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "SpSqMlPBDEdd",
   "metadata": {
    "id": "SpSqMlPBDEdd"
   },
   "outputs": [],
   "source": [
    "max_samples = len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0OihZ57oDEde",
   "metadata": {
    "id": "0OihZ57oDEde"
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2auHzSHODEde",
   "metadata": {
    "id": "2auHzSHODEde"
   },
   "outputs": [],
   "source": [
    "test_features = tf.cast(test_features, tf.float32)\n",
    "tf_lite_ds = tf.data.Dataset.from_tensor_slices((test_features)).batch(1)\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in tf_lite_ds.take(len(tf_lite_ds)):\n",
    "        yield [input_value]\n",
    "    \n",
    "converter.representative_dataset = representative_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "N-fRD_XuDEde",
   "metadata": {
    "id": "N-fRD_XuDEde",
    "outputId": "2ce944a8-43b2-49c9-8c10-729e9b2ca0d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, activation_layer_call_fn, activation_layer_call_and_return_conditional_losses, dense_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\William\\AppData\\Local\\Temp\\tmp_bvlcs0b\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\William\\AppData\\Local\\Temp\\tmp_bvlcs0b\\assets\n",
      "C:\\Users\\William\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13760"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "converter_model = converter.convert()\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"pose.tflite\"\n",
    "converted_model_file.write_bytes(converter_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eBuJ-31nDEdf",
   "metadata": {
    "id": "eBuJ-31nDEdf"
   },
   "source": [
    "In order to integrate converted model into TFLM application we have to save it as a C array. One way to do that is to use **xxd** utility available on Linux or in Cygwin/MinGW terminals on Windows. Open terminal and run following commands:\n",
    "\n",
    "```\n",
    "cd generated/\n",
    "xxd -i emnist_model_int8.tflite > model.h\n",
    "```\n",
    "\n",
    "The model is ready to be integrated into TFLM application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_XoBRPZiDEdf",
   "metadata": {
    "id": "_XoBRPZiDEdf"
   },
   "source": [
    "## Evaluate TensorFlow Lite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "EsewJjN6DEdg",
   "metadata": {
    "id": "EsewJjN6DEdg"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"pose.tflite\"\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=str(converted_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    scale, zero_point = interpreter.get_output_details()[0][\"quantization\"]\n",
    "\n",
    "    prediction_values = []\n",
    "    \n",
    "    for test_data in test_features:\n",
    "        # Pre-processing: add batch dimension, quantize and convert inputs to int8 to match with\n",
    "        # the model's input data format.\n",
    "        test_data = np.expand_dims(test_data, axis=0)\n",
    "        test_data = np.int8(test_data)\n",
    "        interpreter.set_tensor(input_index, test_data)\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Find the letter with highest probability\n",
    "        output = interpreter.tensor(output_index)\n",
    "        result = np.argmax(output()[0])\n",
    "        prediction_values.append(result)\n",
    "    \n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_values)):\n",
    "        if prediction_values[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_values)\n",
    "\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fT4MXDEdg",
   "metadata": {
    "id": "018fT4MXDEdg"
   },
   "source": [
    "Please, keep in mind that full test dataset evaluation on int8 model may take several minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "x2C5qic2DEdh",
   "metadata": {
    "id": "x2C5qic2DEdh",
    "outputId": "d479229f-8c20-4b83-f854-79cbd3235043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5GefgFQhDEdj",
   "metadata": {
    "id": "5GefgFQhDEdj"
   },
   "source": [
    "## Create a test set for target application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wEXgAg1VDEdk",
   "metadata": {
    "id": "wEXgAg1VDEdk"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Import training and testing from dataset_buffer\n",
    "num_of_samples = 25\n",
    "random_test_features = random.sample(range(1, test_features.shape[0]), num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "TLHbM0QmDEdl",
   "metadata": {
    "id": "TLHbM0QmDEdl"
   },
   "outputs": [],
   "source": [
    "samples_file = open(\"generated/test_samples.cpp\", \"w\")\n",
    "\n",
    "samples_file.write(\"#include \\\"test_samples.h\\\"\\n\\n\")\n",
    "samples_file.write(\"const int kNumSamples = \" + str(num_of_samples) + \";\\n\\n\")\n",
    "\n",
    "samples = \"\" \n",
    "samples_array = \"const TestSample test_samples[kNumSamples] = {\"\n",
    "\n",
    "for sample_idx, feature_idx in enumerate(random_test_features, 1):\n",
    "    feature_arr = list(np.array(test_features[feature_idx]).astype(\"int\"))\n",
    "    var_name = \"sample\" + str(sample_idx)\n",
    "    samples += \"TestSample \" + var_name + \" = {\\n\" #+ \"[IMAGE_SIZE] = { \"\n",
    "    samples += \"\\t.label = \" + str(test_labels[feature_idx]) + \",\\n\" \n",
    "    samples += \"\\t.feature = {\\n\"\n",
    "    samples += \"\\t\\t\" + str(feature_arr)\n",
    "    samples += \"\\t}\\n};\\n\\n\"    \n",
    "    samples_array += var_name + \", \"\n",
    "    \n",
    "samples = samples.replace(\"[\", \"\")\n",
    "samples = samples.replace(\"]\", \",\\n\")\n",
    "samples_array += \"};\\n\"\n",
    "\n",
    "samples_file.write(samples);\n",
    "samples_file.write(samples_array);\n",
    "samples_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JtSpvAOlDEdn",
   "metadata": {
    "id": "JtSpvAOlDEdn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pose.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
